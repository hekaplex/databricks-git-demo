{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='additional-resources'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Fine Tuning with PyTorch Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mermaid-py in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from mermaid-py) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" class=\"flowchart\" style=\"max-width: 647.87109375px;\" viewBox=\"0 0 647.87109375 1156.4168701171875\" role=\"graphics-document document\" aria-roledescription=\"flowchart-v2\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.1/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:1px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg p{margin:0;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span{color:#333;}#mermaid-svg .cluster-label span p{background-color:transparent;}#mermaid-svg .label text,#mermaid-svg span{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .rough-node .label text,#mermaid-svg .node .label text,#mermaid-svg .image-shape .label,#mermaid-svg .icon-shape .label{text-anchor:middle;}#mermaid-svg .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg .rough-node .label,#mermaid-svg .node .label,#mermaid-svg .image-shape .label,#mermaid-svg .icon-shape .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .root .anchor path{fill:#333333!important;stroke-width:0;stroke:#333333;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg rect.text{fill:none;stroke-width:0;}#mermaid-svg .icon-shape,#mermaid-svg .image-shape{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .icon-shape p,#mermaid-svg .image-shape p{background-color:rgba(232,232,232, 0.8);padding:2px;}#mermaid-svg .icon-shape rect,#mermaid-svg .image-shape rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g><marker id=\"mermaid-svg_flowchart-v2-pointEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-pointStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossEnd\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossStart\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"root\"><g class=\"clusters\"/><g class=\"edgePaths\"/><g class=\"edgeLabels\"/><g class=\"nodes\"><g class=\"root\" transform=\"translate(0, 0)\"><g class=\"clusters\"><g class=\"cluster \" id=\"subGraph0\" data-look=\"classic\"><rect style=\"\" x=\"8\" y=\"8\" width=\"631.87109375\" height=\"1140.4168853759766\"/><g class=\"cluster-label \" transform=\"translate(283.201171875, 8)\"><foreignObject width=\"81.46875\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>MIT Project</p></span></div></foreignObject></g></g></g><g class=\"edgePaths\"><path d=\"M291.614,133.732L281.287,140.442C270.96,147.151,250.306,160.571,240.054,172.947C229.801,185.324,229.951,196.657,230.025,202.324L230.1,207.991\" id=\"L_A_C_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M230.152,250.99L230.069,257.157C229.986,263.324,229.819,275.657,237.659,288.385C245.499,301.112,261.346,314.234,269.269,320.795L277.192,327.356\" id=\"L_C_D_1\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M392.684,116.283L407.23,125.901C421.775,135.519,450.866,154.755,465.486,170.039C480.106,185.324,480.255,196.657,480.33,202.324L480.404,207.991\" id=\"L_A_B_2\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M480.457,250.99L480.374,257.157C480.29,263.324,480.124,275.657,472.117,288.385C464.11,301.112,448.264,314.234,440.34,320.795L432.417,327.356\" id=\"L_B_D_3\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M106.664,400.704L106.581,412.823C106.497,424.941,106.331,449.179,106.247,469.548C106.164,489.917,106.164,506.417,106.164,524.917C106.164,543.417,106.164,563.917,111.436,581.948C116.707,599.98,127.25,615.542,132.522,623.324L137.793,631.105\" id=\"L_E_F_4\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M153.184,673.417L153.1,683.584C153.017,693.75,152.85,714.084,166.075,734.185C179.3,754.286,205.916,774.155,219.225,784.09L232.533,794.024\" id=\"L_F_G_5\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M290.053,432.727L282.723,439.509C275.393,446.29,260.734,459.854,253.404,474.885C246.074,489.917,246.074,506.417,246.074,524.917C246.074,543.417,246.074,563.917,235.524,582.1C224.974,600.282,203.874,616.148,193.324,624.08L182.774,632.013\" id=\"L_D_F_6\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M446.616,428.331L457.009,435.846C467.401,443.36,488.187,458.388,498.58,474.153C508.973,489.917,508.973,506.417,508.973,524.917C508.973,543.417,508.973,563.917,508.973,585.667C508.973,607.417,508.973,630.417,508.973,655.417C508.973,680.417,508.973,707.417,478.362,731.041C447.751,754.665,386.53,774.913,355.92,785.037L325.309,795.161\" id=\"L_D_G_7\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M319.695,835.417L344.058,843.584C368.421,851.75,417.146,868.084,441.508,887.75C465.871,907.417,465.871,930.417,465.871,951.417C465.871,972.417,465.871,991.417,465.946,1006.584C466.02,1021.75,466.169,1033.084,466.244,1038.751L466.318,1044.417\" id=\"L_G_H_8\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M225.811,835.417L210.453,843.584C195.095,851.75,164.38,868.084,149.099,883.917C133.817,899.75,133.971,915.084,134.047,922.75L134.124,930.417\" id=\"L_G_I_9\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(106.1640625, 522.9168853759766)\"><g class=\"label\" transform=\"translate(-27.3125, -12)\"><foreignObject width=\"54.625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"><p>pytorch</p></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(152.68359375, 734.4168853759766)\"><g class=\"label\" transform=\"translate(-60.0078125, -24)\"><foreignObject width=\"120.015625\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"><p>transfer learning <br />training</p></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(246.07421875, 522.9168853759766)\"><g class=\"label\" transform=\"translate(-45.7265625, -12)\"><foreignObject width=\"91.453125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"><p>training split</p></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(508.97265625, 584.4168853759766)\"><g class=\"label\" transform=\"translate(-67.796875, -12)\"><foreignObject width=\"135.59375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"><p>eval and test splits</p></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(465.87109375, 953.4168853759766)\"><g class=\"label\" transform=\"translate(-45.7265625, -12)\"><foreignObject width=\"91.453125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"><p>training split</p></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(133.6640625, 884.4168853759766)\"><g class=\"label\" transform=\"translate(-67.796875, -12)\"><foreignObject width=\"135.59375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"><p>eval and test splits</p></span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"node default  \" id=\"flowchart-A-0\" transform=\"translate(354.8046875, 90.99520492553711)\"><g class=\"basic label-container\" transform=\"translate(0,-6.75)\"><path d=\"M-94.3046875 -28.75 C-94.3046875 -5.981079411938289, -94.3046875 16.787841176123422, -94.3046875 38.75 C-94.3046875 38.75, -94.3046875 38.75, -94.3046875 38.75 C-93.55813416005165 39.03315774052709, -92.8115808201033 39.316315481054176, -90.7325 40.1048831504914 C-89.50648457259604 40.56519880756432, -88.28046914519206 41.02551446463724, -87.1603125 41.44608473694449 C-86.2270096102692 41.789386473263576, -85.29370672053841 42.13268820958265, -83.588125 42.76006135128997 C-82.34513416070716 43.203186996486934, -81.1021433214143 43.6463126416839, -80.0159375 44.03354450230223 C-79.01866209278509 44.37417772505687, -78.02138668557019 44.714810947811515, -76.44375 45.25367460037316 C-75.26974708540288 45.63308776349705, -74.09574417080577 46.01250092662094, -72.8715625 46.408130813211216 C-71.73751354130147 46.75008153895196, -70.60346458260292 47.092032264692705, -69.299375 47.4852554811875 C-68.05365266846536 47.83011845022069, -66.80793033693072 48.17498141925388, -65.7271875 48.474171835986745 C-64.99292089518137 48.6572606064402, -64.25865429036273 48.84034937689364, -62.155 49.364893833844356 C-60.817588528574284 49.658245243031395, -59.480177057148566 49.95159665221844, -58.582812499999996 50.1484269942772 C-57.216423248309205 50.40410747492588, -55.850033996618414 50.65978795557456, -55.010625 50.81685922604206 C-53.803920881343664 51.00149739068451, -52.59721676268734 51.18613555532696, -51.4384375 51.36344072316426 C-50.33845396633589 51.492528470746855, -49.238470432671775 51.62161621832944, -47.86625 51.782652124249196 C-46.95123381869728 51.856322973277635, -46.03621763739456 51.92999382230607, -44.294062499999995 52.07026024680622 C-43.228809017074944 52.11591600634109, -42.16355553414989 52.16157176587596, -40.721875000000004 52.22336083378167 C-39.739836522376635 52.22804727757907, -38.75779804475327 52.232733721376476, -37.1496875 52.24040788064795 C-36.16905479325782 52.20769110242917, -35.18842208651565 52.174974324210396, -33.57749999999999 52.12122924690479 C-32.73132168138614 52.061014252589224, -31.885143362772283 52.00079925827366, -30.005312500000002 51.8670283943481 C-28.871993692207436 51.744357146535975, -27.73867488441487 51.62168589872385, -26.433125000000004 51.48037223455367 C-25.525631838063685 51.349486928753045, -24.618138676127366 51.21860162295241, -22.86093749999999 50.96516520829126 C-21.65858285245549 50.7502352830288, -20.456228204910985 50.53530535776634, -19.288750000000007 50.326609858614304 C-17.986004197040003 50.05110176621004, -16.68325839408 49.77559367380578, -15.716562499999995 49.571154295756834 C-14.327910814887472 49.235000356664024, -12.939259129774952 48.898846417571214, -12.144374999999997 48.706427084335346 C-11.42224591508828 48.511295310205995, -10.700116830176562 48.31616353607665, -8.572187499999998 47.741160210362395 C-7.5669025302886945 47.443964011716275, -6.561617560577391 47.14676781307016, -5 46.68510090594839 C-3.941516903145354 46.34843451925223, -2.8830338062907086 46.01176813255607, -1.4278125000000017 45.548913222082774 C-0.3345851725153737 45.18018477199693, 0.7586421549692544 44.81145632191107, 2.144375000000011 44.344070343409335 C3.1777143600546953 43.97920047033019, 4.21105372010938 43.614330597251055, 5.716562500000009 43.082738732397324 C6.664629022490228 42.73636667407615, 7.612695544980448 42.38999461575498, 9.288749999999993 41.77765527281665 C10.162833342579283 41.45083166608149, 11.036916685158571 41.12400805934633, 12.860937499999991 40.44199865311811 C13.871787936256483 40.05920233869398, 14.882638372512975 39.676406024269845, 16.433125000000004 39.08925628848505 C17.77700768001414 38.57905605246917, 19.12089036002828 38.06885581645328, 20.005312500000002 37.73308812537291 C21.282481796386143 37.25188678383816, 22.55965109277228 36.77068544230342, 23.5775 36.38718870383377 C24.67299707857 35.98175344178421, 25.76849415714 35.57631817973465, 27.149687500000013 35.065148870516104 C28.351546846602567 34.632868833977334, 29.553406193205117 34.20058879743857, 30.721874999999997 33.780318538756845 C31.81050996937619 33.40405622727583, 32.899144938752386 33.027793915794824, 34.294062499999995 32.54567188160991 C35.70019887094567 32.084333951546085, 37.10633524189135 31.622996021482255, 37.86625000000001 31.373676319087366 C39.135845969948065 30.98360891986201, 40.40544193989612 30.593541520636652, 41.43843749999999 30.276166622575545 C42.74207475374701 29.906867903991056, 44.04571200749404 29.537569185406568, 45.010625000000005 29.264225407715532 C46.05873006821366 28.995419292481824, 47.10683513642732 28.726613177248115, 48.58281250000002 28.348071222526844 C49.36730705569163 28.169940601579462, 50.15180161138325 27.991809980632077, 52.155 27.536955360856528 C53.56214591889824 27.262045735274448, 54.969291837796476 26.98713610969237, 55.727187499999985 26.839068443128134 C56.46849434782903 26.719201612642156, 57.20980119565808 26.599334782156173, 59.299375 26.261457707734817 C60.12183833612742 26.15750355482237, 60.94430167225484 26.053549401909923, 62.87156250000001 25.809955848265425 C64.05112219343695 25.704014449651023, 65.23068188687388 25.598073051036625, 66.44375 25.4891221151627 C67.81529586426892 25.417351705336593, 69.18684172853786 25.345581295510488, 70.0159375 25.302196276567173 C70.85446170834695 25.29019409140485, 71.6929859166939 25.278191906242526, 73.58812499999999 25.25106590324848 C74.63946842958251 25.276135950715748, 75.69081185916501 25.30120599818301, 77.1603125 25.33624730797989 C78.30817232739761 25.407143862170873, 79.45603215479522 25.478040416361853, 80.73249999999999 25.55688033182939 C81.59819599347914 25.64263516017628, 82.46389198695827 25.728389988523173, 84.3046875 25.910737030015426 C84.3046875 24.731058061882745, 84.3046875 23.551379093750064, 84.3046875 20.910737030015426 C85.35970076488292 20.910737030015426, 86.41471402976585 20.910737030015426, 89.3046875 20.910737030015426 C89.3046875 19.77357239595978, 89.3046875 18.636407761904135, 89.3046875 15.910737030015426 C90.3447144876937 15.910737030015426, 91.3847414753874 15.910737030015426, 94.3046875 15.910737030015426 C94.3046875 -2.7932665825404257, 94.3046875 -21.497270195096277, 94.3046875 -38.75 C54.33590032165379 -38.75, 14.367113143307577 -38.75, -84.3046875 -38.75 C-84.3046875 -37.07924061215172, -84.3046875 -35.40848122430344, -84.3046875 -33.75 C-86.20280423975036 -33.75, -88.10092097950073 -33.75, -89.3046875 -33.75 C-89.3046875 -32.531622634157976, -89.3046875 -31.313245268315953, -89.3046875 -28.75 C-90.55464030464235 -28.75, -91.8045931092847 -28.75, -94.3046875 -28.75\" stroke=\"none\" stroke-width=\"0\" fill=\"#ECECFF\" style=\"\"/><path d=\"M-94.3046875 -28.75 C-94.3046875 -2.619390698502066, -94.3046875 23.511218602995868, -94.3046875 38.75 M-94.3046875 -28.75 C-94.3046875 -6.5920533534322665, -94.3046875 15.565893293135467, -94.3046875 38.75 M-94.3046875 38.75 C-94.3046875 38.75, -94.3046875 38.75, -94.3046875 38.75 M-94.3046875 38.75 C-94.3046875 38.75, -94.3046875 38.75, -94.3046875 38.75 M-94.3046875 38.75 C-93.32637868811456 39.12105950491144, -92.34806987622912 39.492119009822886, -90.7325 40.1048831504914 M-94.3046875 38.75 C-92.93535219291662 39.269370647520674, -91.56601688583324 39.78874129504134, -90.7325 40.1048831504914 M-90.7325 40.1048831504914 C-89.87300091893414 40.42758780445498, -89.01350183786828 40.750292458418556, -87.1603125 41.44608473694449 M-90.7325 40.1048831504914 C-89.6200729398145 40.522551298631484, -88.50764587962901 40.94021944677156, -87.1603125 41.44608473694449 M-87.1603125 41.44608473694449 C-86.2624575359512 41.776347475346135, -85.36460257190241 42.10661021374778, -83.588125 42.76006135128997 M-87.1603125 41.44608473694449 C-85.76172887038447 41.96053314776314, -84.36314524076894 42.47498155858178, -83.588125 42.76006135128997 M-83.588125 42.76006135128997 C-82.64547414859028 43.09611593312747, -81.70282329718056 43.43217051496497, -80.0159375 44.03354450230223 M-83.588125 42.76006135128997 C-82.63676439090358 43.09922095761552, -81.68540378180714 43.43838056394108, -80.0159375 44.03354450230223 M-80.0159375 44.03354450230223 C-78.96448198857756 44.392683689780235, -77.91302647715511 44.75182287725824, -76.44375 45.25367460037316 M-80.0159375 44.03354450230223 C-79.22981610091713 44.30205515012199, -78.44369470183425 44.57056579794175, -76.44375 45.25367460037316 M-76.44375 45.25367460037316 C-75.21187202830781 45.651791770280504, -73.97999405661562 46.04990894018784, -72.8715625 46.408130813211216 M-76.44375 45.25367460037316 C-75.31269465264407 45.6192080089131, -74.18163930528814 45.98474141745304, -72.8715625 46.408130813211216 M-72.8715625 46.408130813211216 C-71.45447699663289 46.835425783676314, -70.03739149326579 47.26272075414141, -69.299375 47.4852554811875 M-72.8715625 46.408130813211216 C-72.14560460320922 46.62702950163268, -71.41964670641843 46.84592819005413, -69.299375 47.4852554811875 M-69.299375 47.4852554811875 C-68.27499093832998 47.76884366130995, -67.25060687665997 48.052431841432394, -65.7271875 48.474171835986745 M-69.299375 47.4852554811875 C-68.02296333506442 47.83861441626897, -66.74655167012884 48.191973351350434, -65.7271875 48.474171835986745 M-65.7271875 48.474171835986745 C-64.66590034475358 48.738802910145566, -63.60461318950716 49.00343398430439, -62.155 49.364893833844356 M-65.7271875 48.474171835986745 C-64.31999360273478 48.82505447009963, -62.91279970546956 49.17593710421251, -62.155 49.364893833844356 M-62.155 49.364893833844356 C-61.07265536914473 49.60229820001818, -59.990310738289445 49.839702566192, -58.582812499999996 50.1484269942772 M-62.155 49.364893833844356 C-60.91529277694464 49.63681453187378, -59.67558555388927 49.90873522990321, -58.582812499999996 50.1484269942772 M-58.582812499999996 50.1484269942772 C-57.65860617365007 50.32136564806659, -56.73439984730014 50.49430430185598, -55.010625 50.81685922604206 M-58.582812499999996 50.1484269942772 C-57.44905657617004 50.36057683312029, -56.31530065234007 50.57272667196338, -55.010625 50.81685922604206 M-55.010625 50.81685922604206 C-54.22345821323534 50.937303855780755, -53.43629142647068 51.057748485519454, -51.4384375 51.36344072316426 M-55.010625 50.81685922604206 C-54.11838050386428 50.95338182808826, -53.22613600772857 51.08990443013445, -51.4384375 51.36344072316426 M-51.4384375 51.36344072316426 C-50.140932877169156 51.51570841091892, -48.84342825433831 51.66797609867358, -47.86625 51.782652124249196 M-51.4384375 51.36344072316426 C-50.28094801377887 51.499277038939915, -49.12345852755773 51.63511335471557, -47.86625 51.782652124249196 M-47.86625 51.782652124249196 C-46.99263684230205 51.852989484795536, -46.1190236846041 51.92332684534187, -44.294062499999995 52.07026024680622 M-47.86625 51.782652124249196 C-47.02887759200979 51.850071627324866, -46.19150518401959 51.917491130400535, -44.294062499999995 52.07026024680622 M-44.294062499999995 52.07026024680622 C-42.90625608010091 52.129740320989015, -41.518449660201824 52.18922039517181, -40.721875000000004 52.22336083378167 M-44.294062499999995 52.07026024680622 C-43.15823614518555 52.118940693066186, -42.0224097903711 52.16762113932616, -40.721875000000004 52.22336083378167 M-40.721875000000004 52.22336083378167 C-39.650175647450276 52.22847515353378, -38.57847629490054 52.23358947328588, -37.1496875 52.24040788064795 M-40.721875000000004 52.22336083378167 C-39.91743791954881 52.22719973546626, -39.11300083909761 52.23103863715085, -37.1496875 52.24040788064795 M-37.1496875 52.24040788064795 C-35.97904639057285 52.20135186580408, -34.808405281145696 52.1622958509602, -33.57749999999999 52.12122924690479 M-37.1496875 52.24040788064795 C-35.72463589593857 52.19286398683344, -34.29958429187714 52.14532009301892, -33.57749999999999 52.12122924690479 M-33.57749999999999 52.12122924690479 C-32.730171806465954 52.06093242620552, -31.88284361293191 52.00063560550625, -30.005312500000002 51.8670283943481 M-33.57749999999999 52.12122924690479 C-32.43815121520116 52.04015191475039, -31.298802430402326 51.95907458259599, -30.005312500000002 51.8670283943481 M-30.005312500000002 51.8670283943481 C-28.6253239318335 51.71765743318565, -27.245335363666996 51.56828647202321, -26.433125000000004 51.48037223455367 M-30.005312500000002 51.8670283943481 C-28.63644190058488 51.71886085016814, -27.26757130116976 51.57069330598818, -26.433125000000004 51.48037223455367 M-26.433125000000004 51.48037223455367 C-25.32248389619866 51.3201874457277, -24.211842792397313 51.16000265690172, -22.86093749999999 50.96516520829126 M-26.433125000000004 51.48037223455367 C-25.196428527224096 51.302006817808866, -23.959732054448185 51.123641401064056, -22.86093749999999 50.96516520829126 M-22.86093749999999 50.96516520829126 C-22.10962802643962 50.83086299610196, -21.358318552879243 50.696560783912666, -19.288750000000007 50.326609858614304 M-22.86093749999999 50.96516520829126 C-21.706861405512978 50.75886543705334, -20.552785311025964 50.552565665815415, -19.288750000000007 50.326609858614304 M-19.288750000000007 50.326609858614304 C-18.187077118315173 50.093625193918506, -17.085404236630335 49.86064052922271, -15.716562499999995 49.571154295756834 M-19.288750000000007 50.326609858614304 C-17.89986412644407 50.032884638605, -16.510978252888133 49.7391594185957, -15.716562499999995 49.571154295756834 M-15.716562499999995 49.571154295756834 C-14.949937880024953 49.38557580363175, -14.18331326004991 49.199997311506664, -12.144374999999997 48.706427084335346 M-15.716562499999995 49.571154295756834 C-14.776040085407782 49.34347998558982, -13.835517670815568 49.115805675422806, -12.144374999999997 48.706427084335346 M-12.144374999999997 48.706427084335346 C-11.384627743034422 48.50113022918967, -10.624880486068845 48.295833374044, -8.572187499999998 47.741160210362395 M-12.144374999999997 48.706427084335346 C-11.341379782811686 48.48944388199488, -10.538384565623375 48.27246067965441, -8.572187499999998 47.741160210362395 M-8.572187499999998 47.741160210362395 C-7.345250091043838 47.3784360625785, -6.118312682087678 47.015711914794615, -5 46.68510090594839 M-8.572187499999998 47.741160210362395 C-7.1507433898604695 47.320933310677724, -5.729299279720941 46.90070641099305, -5 46.68510090594839 M-5 46.68510090594839 C-3.6237592047435987 46.247366928769495, -2.2475184094871974 45.809632951590594, -1.4278125000000017 45.548913222082774 M-5 46.68510090594839 C-3.874359261138343 46.32707402635374, -2.7487185222766866 45.969047146759095, -1.4278125000000017 45.548913222082774 M-1.4278125000000017 45.548913222082774 C-0.5035035317108542 45.23715828812783, 0.4208054365782934 44.92540335417289, 2.144375000000011 44.344070343409335 M-1.4278125000000017 45.548913222082774 C-0.20337236282518067 45.13592874698537, 1.0210677743496404 44.72294427188797, 2.144375000000011 44.344070343409335 M2.144375000000011 44.344070343409335 C3.31537897842535 43.93059139399565, 4.486382956850689 43.51711244458196, 5.716562500000009 43.082738732397324 M2.144375000000011 44.344070343409335 C3.1818551398103203 43.9777383700345, 4.21933527962063 43.611406396659675, 5.716562500000009 43.082738732397324 M5.716562500000009 43.082738732397324 C6.967270664418518 42.625797841655974, 8.217978828837026 42.16885695091463, 9.288749999999993 41.77765527281665 M5.716562500000009 43.082738732397324 C6.76419791437491 42.699989604314986, 7.811833328749811 42.31724047623265, 9.288749999999993 41.77765527281665 M9.288749999999993 41.77765527281665 C10.589671382042933 41.291235045537704, 11.890592764085872 40.80481481825875, 12.860937499999991 40.44199865311811 M9.288749999999993 41.77765527281665 C10.629265835012523 41.27643050540307, 11.969781670025052 40.77520573798949, 12.860937499999991 40.44199865311811 M12.860937499999991 40.44199865311811 C14.21794283007039 39.92811784506448, 15.574948160140789 39.41423703701084, 16.433125000000004 39.08925628848505 M12.860937499999991 40.44199865311811 C14.115067894747302 39.96707528592402, 15.36919828949461 39.49215191872992, 16.433125000000004 39.08925628848505 M16.433125000000004 39.08925628848505 C17.839581752606595 38.555300030399735, 19.24603850521319 38.02134377231441, 20.005312500000002 37.73308812537291 M16.433125000000004 39.08925628848505 C17.772360799702803 38.58082022390082, 19.1115965994056 38.0723841593166, 20.005312500000002 37.73308812537291 M20.005312500000002 37.73308812537291 C20.85827420022854 37.41171623239903, 21.711235900457076 37.09034433942515, 23.5775 36.38718870383377 M20.005312500000002 37.73308812537291 C21.10479379592824 37.31883460699434, 22.20427509185648 36.904581088615785, 23.5775 36.38718870383377 M23.5775 36.38718870383377 C24.54539099736676 36.02897949649837, 25.513281994733518 35.670770289162974, 27.149687500000013 35.065148870516104 M23.5775 36.38718870383377 C24.56180356248874 36.022905329098656, 25.546107124977482 35.65862195436354, 27.149687500000013 35.065148870516104 M27.149687500000013 35.065148870516104 C28.141179069723663 34.70853308747993, 29.132670639447312 34.351917304443745, 30.721874999999997 33.780318538756845 M27.149687500000013 35.065148870516104 C28.140501589663298 34.70877676083994, 29.131315679326583 34.35240465116377, 30.721874999999997 33.780318538756845 M30.721874999999997 33.780318538756845 C32.04827897034386 33.321876693805685, 33.37468294068773 32.863434848854524, 34.294062499999995 32.54567188160991 M30.721874999999997 33.780318538756845 C31.607829080030925 33.47410834030117, 32.49378316006185 33.167898141845505, 34.294062499999995 32.54567188160991 M34.294062499999995 32.54567188160991 C35.19754015317572 32.24925076699591, 36.10101780635144 31.952829652381894, 37.86625000000001 31.373676319087366 M34.294062499999995 32.54567188160991 C35.0429779878265 32.29996091922704, 35.79189347565299 32.054249956844174, 37.86625000000001 31.373676319087366 M37.86625000000001 31.373676319087366 C38.73803929213734 31.105830020023866, 39.60982858427466 30.837983720960366, 41.43843749999999 30.276166622575545 M37.86625000000001 31.373676319087366 C39.175294224418394 30.97148893965614, 40.48433844883679 30.56930156022491, 41.43843749999999 30.276166622575545 M41.43843749999999 30.276166622575545 C42.621816824068624 29.940934972266533, 43.80519614813725 29.60570332195752, 45.010625000000005 29.264225407715532 M41.43843749999999 30.276166622575545 C42.684094285604736 29.923292804803246, 43.92975107120948 29.57041898703095, 45.010625000000005 29.264225407715532 M45.010625000000005 29.264225407715532 C46.37683460402546 28.913835444542293, 47.74304420805092 28.563445481369058, 48.58281250000002 28.348071222526844 M45.010625000000005 29.264225407715532 C46.3667138820111 28.91643109267963, 47.722802764022184 28.568636777643732, 48.58281250000002 28.348071222526844 M48.58281250000002 28.348071222526844 C49.50587878014595 28.1384759251917, 50.42894506029188 27.928880627856557, 52.155 27.536955360856528 M48.58281250000002 28.348071222526844 C49.76606221548926 28.079397584160937, 50.9493119309785 27.81072394579503, 52.155 27.536955360856528 M52.155 27.536955360856528 C53.20834783891697 27.33116614161828, 54.261695677833934 27.12537692238003, 55.727187499999985 26.839068443128134 M52.155 27.536955360856528 C53.15084675569372 27.34239994548124, 54.14669351138744 27.14784453010595, 55.727187499999985 26.839068443128134 M55.727187499999985 26.839068443128134 C56.62360288547158 26.694121082436645, 57.52001827094317 26.549173721745156, 59.299375 26.261457707734817 M55.727187499999985 26.839068443128134 C56.6305483688869 26.692998021067893, 57.53390923777381 26.546927599007653, 59.299375 26.261457707734817 M59.299375 26.261457707734817 C60.27255138738766 26.138454380362656, 61.24572777477532 26.0154510529905, 62.87156250000001 25.809955848265425 M59.299375 26.261457707734817 C60.696138753232994 26.08491562201727, 62.09290250646599 25.908373536299727, 62.87156250000001 25.809955848265425 M62.87156250000001 25.809955848265425 C63.79073865290068 25.72740063062522, 64.70991480580135 25.644845412985013, 66.44375 25.4891221151627 M62.87156250000001 25.809955848265425 C64.12719235604813 25.697182256702508, 65.38282221209626 25.58440866513959, 66.44375 25.4891221151627 M66.44375 25.4891221151627 C67.55575989228277 25.43093273354668, 68.66776978456552 25.37274335193066, 70.0159375 25.302196276567173 M66.44375 25.4891221151627 C67.35820985098583 25.441270154842176, 68.27266970197168 25.393418194521654, 70.0159375 25.302196276567173 M70.0159375 25.302196276567173 C71.17714963194418 25.285575309776235, 72.33836176388833 25.2689543429853, 73.58812499999999 25.25106590324848 M70.0159375 25.302196276567173 C70.83019333595959 25.290541455853106, 71.64444917191918 25.278886635139035, 73.58812499999999 25.25106590324848 M73.58812499999999 25.25106590324848 C74.60002139277563 25.275195307480278, 75.61191778555128 25.299324711712075, 77.1603125 25.33624730797989 M73.58812499999999 25.25106590324848 C74.61125272051179 25.275463126645302, 75.63438044102357 25.299860350042128, 77.1603125 25.33624730797989 M77.1603125 25.33624730797989 C77.90787032554219 25.3824195605707, 78.65542815108438 25.428591813161507, 80.73249999999999 25.55688033182939 M77.1603125 25.33624730797989 C78.37672950744444 25.411378236189684, 79.59314651488887 25.48650916439948, 80.73249999999999 25.55688033182939 M80.73249999999999 25.55688033182939 C81.74807941876965 25.657482436246227, 82.76365883753931 25.758084540663067, 84.3046875 25.910737030015426 M80.73249999999999 25.55688033182939 C81.84149210173581 25.666735786906884, 82.95048420347165 25.776591241984374, 84.3046875 25.910737030015426 M84.3046875 25.910737030015426 C84.3046875 24.75885624735714, 84.3046875 23.606975464698856, 84.3046875 20.910737030015426 M84.3046875 25.910737030015426 C84.3046875 24.640374672129045, 84.3046875 23.370012314242665, 84.3046875 20.910737030015426 M84.3046875 20.910737030015426 C86.28290671100268 20.910737030015426, 88.26112592200535 20.910737030015426, 89.3046875 20.910737030015426 M84.3046875 20.910737030015426 C85.99109279207838 20.910737030015426, 87.67749808415674 20.910737030015426, 89.3046875 20.910737030015426 M89.3046875 20.910737030015426 C89.3046875 19.278672213699863, 89.3046875 17.6466073973843, 89.3046875 15.910737030015426 M89.3046875 20.910737030015426 C89.3046875 18.953199247788348, 89.3046875 16.99566146556127, 89.3046875 15.910737030015426 M89.3046875 15.910737030015426 C90.91167612619111 15.910737030015426, 92.51866475238224 15.910737030015426, 94.3046875 15.910737030015426 M89.3046875 15.910737030015426 C91.20956063080965 15.910737030015426, 93.11443376161928 15.910737030015426, 94.3046875 15.910737030015426 M94.3046875 15.910737030015426 C94.3046875 4.596758698182395, 94.3046875 -6.717219633650636, 94.3046875 -38.75 M94.3046875 15.910737030015426 C94.3046875 2.2233241552493883, 94.3046875 -11.46408871951665, 94.3046875 -38.75 M94.3046875 -38.75 C52.05777095971518 -38.75, 9.810854419430356 -38.75, -84.3046875 -38.75 M94.3046875 -38.75 C23.980683955117428 -38.75, -46.343319589765144 -38.75, -84.3046875 -38.75 M-84.3046875 -38.75 C-84.3046875 -37.59717984959783, -84.3046875 -36.44435969919565, -84.3046875 -33.75 M-84.3046875 -38.75 C-84.3046875 -36.81774191367347, -84.3046875 -34.88548382734695, -84.3046875 -33.75 M-84.3046875 -33.75 C-85.80902198632867 -33.75, -87.31335647265733 -33.75, -89.3046875 -33.75 M-84.3046875 -33.75 C-85.7328279565222 -33.75, -87.1609684130444 -33.75, -89.3046875 -33.75 M-89.3046875 -33.75 C-89.3046875 -32.37844296094224, -89.3046875 -31.00688592188447, -89.3046875 -28.75 M-89.3046875 -33.75 C-89.3046875 -31.932274448135807, -89.3046875 -30.114548896271618, -89.3046875 -28.75 M-89.3046875 -28.75 C-90.63749303297543 -28.75, -91.97029856595086 -28.75, -94.3046875 -28.75 M-89.3046875 -28.75 C-91.06442279882972 -28.75, -92.82415809765943 -28.75, -94.3046875 -28.75\" stroke=\"#9370DB\" stroke-width=\"1.3\" fill=\"none\" style=\"\"/><g><path d=\"M-89.3046875 -28.75 C-25.98169310819263 -28.75, 37.34130128361474 -28.75, 84.3046875 -28.75 C84.3046875 -8.9122059901092, 84.3046875 10.9255880197816, 84.3046875 20.910737030015426 C86.0386411346869 20.910737030015426, 87.77259476937378 20.910737030015426, 89.3046875 20.910737030015426 C89.3046875 9.07310491579875, 89.3046875 -2.7645271984179267, 89.3046875 -33.75 C18.984319006037225 -33.75, -51.33604948792555 -33.75, -89.3046875 -33.75 C-89.3046875 -32.02420093683095, -89.3046875 -30.29840187366191, -89.3046875 -28.75\" stroke=\"none\" stroke-width=\"0\" fill=\"#ECECFF\" style=\"\"/><path d=\"M-89.3046875 -28.75 C-50.63308049432963 -28.75, -11.961473488659266 -28.75, 84.3046875 -28.75 M-89.3046875 -28.75 C-24.040960905891595 -28.75, 41.22276568821681 -28.75, 84.3046875 -28.75 M84.3046875 -28.75 C84.3046875 -12.659253431741373, 84.3046875 3.431493136517254, 84.3046875 20.910737030015426 M84.3046875 -28.75 C84.3046875 -15.534067009239902, 84.3046875 -2.318134018479803, 84.3046875 20.910737030015426 M84.3046875 20.910737030015426 C86.24744700055163 20.910737030015426, 88.19020650110328 20.910737030015426, 89.3046875 20.910737030015426 M84.3046875 20.910737030015426 C86.00939307286765 20.910737030015426, 87.7140986457353 20.910737030015426, 89.3046875 20.910737030015426 M89.3046875 20.910737030015426 C89.3046875 0.9856542266894444, 89.3046875 -18.939428576636537, 89.3046875 -33.75 M89.3046875 20.910737030015426 C89.3046875 5.627712976586253, 89.3046875 -9.65531107684292, 89.3046875 -33.75 M89.3046875 -33.75 C19.17638553978189 -33.75, -50.95191642043622 -33.75, -89.3046875 -33.75 M89.3046875 -33.75 C23.203146867291707 -33.75, -42.898393765416586 -33.75, -89.3046875 -33.75 M-89.3046875 -33.75 C-89.3046875 -32.41543946120061, -89.3046875 -31.08087892240123, -89.3046875 -28.75 M-89.3046875 -33.75 C-89.3046875 -32.472421313028065, -89.3046875 -31.194842626056126, -89.3046875 -28.75\" stroke=\"#9370DB\" stroke-width=\"1.3\" fill=\"none\" style=\"\"/></g></g><g class=\"label\" style=\"\" transform=\"translate(-79.3046875, -13.75)\"><rect/><foreignObject width=\"148.609375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Sample PDFs of Book</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-C-2\" transform=\"translate(229.65234375, 230.99040985107422)\"><polygon points=\"-19.5,0 139.953125,0 159.453125,-39 0,-39\" class=\"label-container\" transform=\"translate(-69.9765625,19.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-62.4765625, -12)\"><rect/><foreignObject width=\"124.953125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Behaviors Prompt</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-D-4\" transform=\"translate(354.8046875, 380.7036476135254)\"><path d=\"M0,15.808823529411764 a107.5,15.808823529411764 0,0,0 215,0 a107.5,15.808823529411764 0,0,0 -215,0 l0,78.80882352941177 a107.5,15.808823529411764 0,0,0 215,0 l0,-78.80882352941177\" class=\"basic label-container\" style=\"\" label-offset-y=\"15.808823529411764\" transform=\"translate(-107.5, -55.21323529411765)\"/><g class=\"label\" style=\"\" transform=\"translate(-100, -14)\"><rect/><foreignObject width=\"200\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\"><span class=\"nodeLabel \"><p>Supervised Learning Pairs Dataset</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-B-6\" transform=\"translate(479.95703125, 230.99040985107422)\"><polygon points=\"-19.5,0 182.65625,0 202.15625,-39 0,-39\" class=\"label-container\" transform=\"translate(-91.328125,19.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-83.828125, -12)\"><rect/><foreignObject width=\"167.65625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Chart Aspects Response</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-E-9\" transform=\"translate(106.1640625, 380.7036476135254)\"><polygon points=\"0,0 42.5625,0 42.5625,-39 0,-39 0,0 -8,0 50.5625,0 50.5625,-39 -8,-39 -8,0\" class=\"label-container\" transform=\"translate(-21.28125,19.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-13.78125, -12)\"><rect/><foreignObject width=\"27.5625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>LLM</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-F-10\" transform=\"translate(152.68359375, 653.4168853759766)\"><polygon points=\"0,0 178.09375,0 178.09375,-39 0,-39 0,0 -8,0 186.09375,0 186.09375,-39 -8,-39 -8,0\" class=\"label-container\" transform=\"translate(-89.046875,19.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-81.546875, -12)\"><rect/><foreignObject width=\"163.09375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Custom Pytorch Layers</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-G-12\" transform=\"translate(261.4140625, 815.4168853759766)\"><polygon points=\"9.75,0 150.515625,0 160.265625,-19.5 150.515625,-39 9.75,-39 0,-19.5\" class=\"label-container\" transform=\"translate(-80.1328125,19.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-62.8828125, -12)\"><rect/><foreignObject width=\"125.765625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Fine tuned model</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-H-18\" transform=\"translate(465.87109375, 1079.4168853759766)\"><polygon points=\"-31.5,0 215,0 246.5,-63 0,-63\" class=\"label-container\" transform=\"translate(-107.5,31.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-100, -24)\"><rect/><foreignObject width=\"200\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\"><span class=\"nodeLabel \"><p>Loss Metric and initial metrics</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-I-20\" transform=\"translate(133.6640625, 953.4168853759766)\"><polygon points=\"-19.5,0 129.5625,0 149.0625,-39 0,-39\" class=\"label-container\" transform=\"translate(-64.78125,19.5)\"/><g class=\"label\" style=\"\" transform=\"translate(-57.28125, -12)\"><rect/><foreignObject width=\"114.5625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Final Evaluation</p></span></div></foreignObject></g></g></g></g></g></g></g></svg>"
      ],
      "text/plain": [
       "<mermaid.__main__.Mermaid at 0x22da8bb2d20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install mermaid-py\n",
    "\n",
    "import mermaid as md\n",
    "from mermaid.graph import Graph\n",
    "\n",
    "sequence = Graph('Astrobot',\"\"\"\n",
    "flowchart TD\n",
    "subgraph MIT Project\n",
    "A@{ shape: docs, label: \"Sample PDFs of Book\" }-->C[/Behaviors Prompt/]\n",
    "C-->D[(Supervised Learning Pairs Dataset)]\n",
    "A-->B[/Chart Aspects Response/]\n",
    "B-->D\n",
    "E[[LLM]]-- pytorch --->F[[Custom Pytorch Layers]]\n",
    "F-- transfer learning \n",
    "training ---G{{Fine tuned model}}\n",
    "D-- training split --->F\n",
    "D-- eval and test splits --->G\n",
    "G-- training split --->H[/Loss Metric and initial metrics/]\n",
    "G-- eval and test splits-->I[/Final Evaluation/]\n",
    "end\n",
    "\n",
    "\"\"\")\n",
    "render = md.Mermaid(sequence)\n",
    "render\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mermaid-py\n",
      "  Downloading mermaid_py-0.7.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from mermaid-py) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\planutary\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2024.12.14)\n",
      "Downloading mermaid_py-0.7.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: mermaid-py\n",
      "Successfully installed mermaid-py-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install mermaid-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - IMDB\n",
    "\n",
    "[A subset of the Internet Movie Database (IMDB)](https://pytorch-geometric.readthedocs.io/en/2.4.0/generated/torch_geometric.datasets.IMDB.html), as collected in the “MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding” paper. IMDB is a heterogeneous graph containing three types of entities - movies (4,278 nodes), actors (5,257 nodes), and directors (2,081 nodes). The movies are divided into three classes (action, comedy, drama) according to their genre. Movie features correspond to elements of a bag-of-words representation of its plot keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 08:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=0.004154805852022643, metrics={'train_runtime': 533.3514, 'train_samples_per_second': 11.25, 'train_steps_per_second': 1.406, 'total_flos': 0.0, 'train_loss': 0.004154805852022643, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "#from torchtune.models import TorchtuneModelWrapper  # Correct way to use torchtune\n",
    "\n",
    "# Load Dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "train_texts, train_labels = dataset['train']['text'][:2000], dataset['train']['label'][:2000]\n",
    "test_texts, test_labels = dataset['test']['text'][:500], dataset['test']['label'][:500]  \n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize the Dataset\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "test_encodings = tokenize_function(test_texts)\n",
    "\n",
    "# Convert to Torch Dataset\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])  # Ensure 'labels' key exists\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "\n",
    "### [DiStillBERT](https://huggingface.co/distilbert/distilbert-base-uncased)\n",
    "\n",
    "DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts using the BERT base model. More precisely, it was pretrained with three objectives:\n",
    "\n",
    "* Distillation loss: the model was trained to return the same probabilities as the BERT base model.\n",
    "* Masked language modeling (MLM): this is part of the original training loss of the BERT base model. When taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
    "* Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)\n",
    "\n",
    "# Define Custom Model\n",
    "class CustomDistilBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDistilBERT, self).__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.custom_layer = nn.Linear(768, 256)  # Custom Layer\n",
    "        self.activation = nn.LeakyReLU()         # Activation Function\n",
    "        self.dropout = nn.Dropout(0.3)           # Regularization\n",
    "        self.classifier = nn.Linear(256, 2)      # Output Layer for Binary Classification\n",
    "        self.loss_fn = nn.CrossEntropyLoss()     # Loss function\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        x = self.custom_layer(hidden_state)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "# ✅ Wrap Model with `torchtune` (if applying efficient fine-tuning methods)\n",
    "wrapped_model = CustomDistilBERT()\n",
    "#wrapped_model = TorchtuneModelWrapper(model)  # Only needed if using PEFT\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Use Hugging Face Trainer\n",
    "trainer = Trainer(\n",
    "    model=wrapped_model,  # Keep using HF Trainer\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDistilBERT(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (custom_layer): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.01)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(wrapped_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDistilBERT(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (custom_layer): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (activation): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "wrapped_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.8206795579753816e-05,\n",
       " 'eval_runtime': 6.3949,\n",
       " 'eval_samples_per_second': 78.187,\n",
       " 'eval_steps_per_second': 9.852,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Load the accuracy metric from the evaluate module\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Evaluate the model using the Trainer's built-in evaluation method\n",
    "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"eval\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planutary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
